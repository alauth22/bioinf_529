{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Before Class\n",
    "In class today we will be implementing the Viterbi algorithm to identify the most likely path through states given model parameters.\n",
    "Prior to class, please do the following:\n",
    "1. Review slides on Hidden Markov models in detail\n",
    "* Focus on how to conceptually translate the algorithm to code\n",
    "* Understand what argmax versus max means\n",
    "* How does one implement a max function? argmax?\n",
    "* Take a look at what arithmetic underflow is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Learning Objectives\n",
    "\n",
    "1. Conceptually understand Hidden Markov Models\n",
    "* Implement a basic HMM\n",
    "* Implement the Viterbi algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last class we described Markov chains. Here we expand this idea to the concept of a hidden state variable along with observed emissions from the model. We will be using the example of CpG islands from the lecture slides. I have provided the class structure of a simple HMM below. All parameters to this model must be provided as inputs, so essentially this is a class containing the parameters described below:\n",
    "\n",
    "We define a categorical Hidden Markov Model as $M = (\\Sigma, Q, \\Theta)$ with the following parameters:\n",
    "\n",
    "$\\Sigma$ : Finite alphabet of symbols (eg. A, C, G, T)\n",
    "\n",
    "$Q$ : Finite discrete hidden states\n",
    "\n",
    "$\\Theta$: set of probabilities containing: $A$ as transition probabilites $a_{kl}$ for all $k,l \\in Q$ and $E$ as emission probabilities $e_k(\\sigma)$ for all $k \\in Q$ and $\\sigma \\in \\Sigma$ and $B$ as starting probabilities $b_k$ for all $k \\in Q$.\n",
    "\n",
    "We also define a number of $T$ emissions as $y_t = 1 \\dots T$ that are drawn from $\\Sigma$ and hidden states as $\\pi_t = 1 \\dots T$ that are drawn from $Q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal today will be to estimate $\\pi^*$, the most probable path through the hidden states $Q$ when a HMM $M$ is provided.\n",
    "\n",
    "We will be following the definition described in the slides as described below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Viterbi algorithm\n",
    "\n",
    "To estimate $\\pi^*$, the most probable path through the hidden states, we will use the Viterbi algorithm, which is a dynamic programming exercise. Calculate viterbi algorithm $v()$ as:\n",
    "\n",
    "Initialization ($i = 0$): $v_{k}(i) = e_{k}(\\sigma)b_{k}$.\n",
    "\n",
    "Recursion ($i = 1 \\dots T$): \n",
    "$v_{l}(i) = e_{l}(x_{i})$ max$_{k}(v_{k}(i-1)a_{kl})$;  ptr$_{i}(l) = $ argmax$_{k}(v_{k}(i-1)a_{kl})$.\n",
    "\n",
    "Termination: $P(x, \\pi^{*}) =$ max$_{k}(v_{k}(l)a_{k0})$; $\\pi^{*}_{l} = $ argmax$_{k}(v_{k}(l)a_{k0})$.\n",
    "\n",
    "Traceback: ($i = T\\dots1$): $\\pi^{*}_{i-1} = $ ptr$_{i}(\\pi^{*}_{i})$.\n",
    "\n",
    "A few implementation notes:\n",
    "1. Break the code up into each of the above phases of the algorithm!\n",
    "2. You will probably want to move all of your probabilities into log space so that you don't get underflow errors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM(object):\n",
    "    \"\"\"Main class for HMM objects\n",
    "    \n",
    "    Class for holding HMM parameters and to allow for implementation of\n",
    "    functions associated with HMMs\n",
    "    \n",
    "    Private Attributes:\n",
    "        _alphabet (set): The alphabet of emissions\n",
    "        _hidden_states (set): Hidden states in the model\n",
    "        _transitions (dict(dict)): A dictionary of transition probabilities\n",
    "        _emissions (dict(dict)): A dictionary of emission probabilities\n",
    "        _initial (dict): A dictionary of initial state probabilities\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alphabet, hidden_states, A=None, E=None, B=None):\n",
    "        self._alphabet = set(alphabet)\n",
    "        self._hidden_states = set(hidden_states)\n",
    "        self._transitions = A\n",
    "        self._emissions = E\n",
    "        self._initial = B\n",
    "        \n",
    "    def _emit(self, cur_state, symbol):\n",
    "        return self._emissions[cur_state][symbol]\n",
    "    \n",
    "    def _transition(self, cur_state, next_state):\n",
    "        return self._transitions[cur_state][next_state]\n",
    "    \n",
    "    def _init(self, cur_state):\n",
    "        return self._initial[cur_state]\n",
    "\n",
    "    def _states(self):\n",
    "        for k in self._hidden_states: #will want to use these for states. \n",
    "            yield k\n",
    "        \n",
    "    def viterbi(self, sequence):\n",
    "        \"\"\" The viterbi algorithm for decoding a string using a HMM\n",
    "\n",
    "        Args:\n",
    "            sequence (list): a list of valid emissions from the HMM\n",
    "\n",
    "        Returns:\n",
    "            result (list): optimal path through HMM given the model parameters\n",
    "                           using the Viterbi algorithm\n",
    "        \n",
    "        Pseudocode for Viterbi:\n",
    "            Initialization (ğ‘–=0): ğ‘£ğ‘˜(ğ‘–)=ğ‘’ğ‘˜(ğœ)ğ‘ğ‘˜.\n",
    "            Recursion (ğ‘–=1â€¦ğ‘‡): ğ‘£ğ‘™(ğ‘–)=ğ‘’ğ‘™(ğ‘¥ğ‘–) maxğ‘˜(ğ‘£ğ‘˜(ğ‘–âˆ’1)ğ‘ğ‘˜ğ‘™); \n",
    "            \n",
    "            for each observation, calclate all probabilties that you came from. \n",
    "            take the max of the value, and keep track with ptr(trace back array), which state you chose that was the max, \n",
    "            keep track of which five you came from. \n",
    "            \n",
    "            pick the largest value, that's the optimal state, then trace back through. \n",
    "            \n",
    "                                ptrğ‘–(ğ‘™)= argmaxğ‘˜(ğ‘£ğ‘˜(ğ‘–âˆ’1)ğ‘ğ‘˜ğ‘™).\n",
    "            Termination: ğ‘ƒ(ğ‘¥,ğœ‹âˆ—)= maxğ‘˜(ğ‘£ğ‘˜(ğ‘™)ğ‘ğ‘˜0); \n",
    "                             ğœ‹âˆ—ğ‘™= argmaxğ‘˜(ğ‘£ğ‘˜(ğ‘™)ğ‘ğ‘˜0).\n",
    "            Traceback: (ğ‘–=ğ‘‡â€¦1): ğœ‹âˆ—ğ‘–âˆ’1= ptrğ‘–(ğœ‹âˆ—ğ‘–).\n",
    "        \"\"\"\n",
    "        \n",
    "        grid = {}\n",
    "        backward_pointer = []\n",
    "        \n",
    "        for state in self._states(): #island or genome\n",
    "            grid[state] = np.log10(self._init(state)) + np.log10(self._emit(state, sequence[0])) # b * e(0) for all k\n",
    "        \n",
    "        for pos in range(1, len(sequence)): #need to exclude the first element since that is already done. \n",
    "            grid_next = {}\n",
    "            backward_pointer_next = {}\n",
    "            \n",
    "            for next_state in self._states():\n",
    "                k = {}\n",
    "                for cur_state in self._states():\n",
    "                    k[cur_state] = grid[cur_state] + np.log10(self._transition(cur_state, next_state))\n",
    "                max_value = max(k, key = k.get)\n",
    "                print(max_value)\n",
    "                grid_next[next_state] = np.log10(self._emit(next_state, sequence[pos])) + k[max_value]\n",
    "                backward_pointer_next[next_state] = max_value\n",
    "            \n",
    "            grid = grid_next \n",
    "            backward_pointer.append(backward_pointer_next)\n",
    "            \n",
    "        \n",
    "        max_final_state = max(grid, key = grid.get) #find the max but only return the key \n",
    "        max_final_prob = grid[max_final_state] #use the key for that max to get the value and set that equal to this variable. \n",
    "        \n",
    "        # result = [max_final_state]\n",
    "        # print(result)\n",
    "        \n",
    "        result = [max_final_state]\n",
    "        for i in reversed(range(len(sequence) - 1)): #you have to subtract one to remain within the index range. \n",
    "            result.append(backward_pointer[i][max_final_state]) #for every position give me the max final state, which we have calculated above. \n",
    "            # print(backward_pointer[i][max_final_state])\n",
    "                  \n",
    "                  \n",
    "            # max_final_state = traceback[t][max_final_state]\n",
    "            # print(max_final_state)\n",
    "            \n",
    "        return result[::-1]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this is my work that was not working for some reason. \n",
    "\n",
    "# # move everything to log space to avoid underflow errors.\n",
    "#         # Initialization (ğ‘–=0): ğ‘£ğ‘˜(ğ‘–)=ğ‘’ğ‘˜(ğœ)ğ‘ğ‘˜.\n",
    "#         grid = {} #will hold the vi data that's in the matrix in the PPT. So it holds all the probabilites at a given state. \n",
    "#         #make this a dictionary \"KEY\" = \"PROB\"\n",
    "#         #will only keep the previous column because those values are what are needed to calculate the next column. So we only need the previous column. \n",
    "        \n",
    "#         backward_pointer = [] #a list of dictionaries. we need to keep track of all the traceback data. a list for every position and a dictionary for every \n",
    "#         #state, will need all the traceback data. \n",
    "#         #initialize the grid\n",
    "#         #Initialization (ğ‘–=0): ğ‘£ğ‘˜(ğ‘–)=ğ‘’ğ‘˜(ğœ)ğ‘ğ‘˜.\n",
    "#         #whatever bases emitted in first position x prob of going into that at the beginning of the state. \n",
    "        \n",
    "#         #so I need to go through each state. \n",
    "#         for state in self._states(): #for every hidden state either island or genome. \n",
    "#             #we need to multiply the emission state by the beginning probabilities\n",
    "#             grid[state] = np.log10(self.init(state)) + np.log10(self._emit(state, sequence[0])) #b * e(0) for all k.  \n",
    "#             #we want the first nc in the sequence. \n",
    "            \n",
    "#         # print(grid)\n",
    "        \n",
    "\n",
    "#         #Recursion (ğ‘–=1â€¦ğ‘‡): ğ‘£ğ‘™(ğ‘–)=ğ‘’ğ‘™(ğ‘¥ğ‘–) maxğ‘˜(ğ‘£ğ‘˜(ğ‘–âˆ’1)ğ‘ğ‘˜ğ‘™); loop through all the states. \n",
    "#         #ptr ğ‘–(ğ‘™)=  argmax ğ‘˜(ğ‘£ğ‘˜(ğ‘–âˆ’1)ğ‘ğ‘˜ğ‘™) completing the rest of the PPT and calcualting the v position and keeping track of the pointer. \n",
    "#         for pos in range(1, len(sequence)): #want to exclude the first position since it's already calculated. \n",
    "#             grid_next = {}\n",
    "#             backward_pointer_next = {}\n",
    "#             #vl is next item in the grid = emission at next pos times max of the prob of one of the previous states times the transition from that state.\n",
    "            \n",
    "#             #emission of the next position x max of probability of one of the previous states AFTER calculating both states x transition of that state \n",
    "#             #for every possible next state \n",
    "#             for next_state in self._states(): #genome or CpG island, for every possible next state. \n",
    "#                 #next state relies on the max probabilties of each current state. So we need a for loop to calculate the maximum for each state\n",
    "#                 k = {}  #this will contain the max\n",
    "#                 #calcualte the two values for each current and take the max\n",
    "#                 for cur_state in self._states(): #going to take the max from these two. \n",
    "#                     #now going to fill in the empty dictionary to get the values to take the max. \n",
    "#                     #here we're adding the log space of the value from the first column in the grid to the transition state. \n",
    "                    \n",
    "#                     #ğ‘£ğ‘™(ğ‘–)=ğ‘’ğ‘™(ğ‘¥ğ‘–) maxğ‘˜(ğ‘£ğ‘˜(ğ‘–âˆ’1)ğ‘ğ‘˜ğ‘™)\n",
    "#                     #this is just filling in the empty k dictionary \n",
    "#                     k[cur_state] = grid[cur_state] + np.log10(self._transition(cur_state, next_state))\n",
    "               \n",
    "               \n",
    "#                 #this is the equation to find the max in k, and ton only return the key and not the value. \n",
    "#                 value_max = max(k, key = k.get)\n",
    "#                 #now we have the max value so we need to multiply it by the emission from the next state. \n",
    "#                 #now we want to grab the maximum value from k. \n",
    "#                 grid_next[next_state] = k[value_max] + np.log10(self._emit(next_state, sequence[pos])\n",
    "                \n",
    "#                 #ptr ğ‘–(ğ‘™)=  argmax ğ‘˜(ğ‘£ğ‘˜(ğ‘–âˆ’1)ğ‘ğ‘˜ğ‘™) keep track of the pointer. It's just the argmax. \n",
    "#                 backward_pointer_next[next_state] = \n",
    "                \n",
    "#                 #Overwrite the exisiting grid values so that it is always the most previous values. \n",
    "#                 grid = grid_next \n",
    "#                 backward_pointer.append(backward_pointer_next) #appending the dictionary. \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "#         #Termination: ğ‘ƒ(ğ‘¥,ğœ‹âˆ—)= maxğ‘˜(ğ‘£ğ‘˜(ğ‘™)ğ‘ğ‘˜0); \n",
    "                             \n",
    "#         # ğœ‹âˆ—ğ‘™= argmaxğ‘˜(ğ‘£ğ‘˜(ğ‘™)ğ‘ğ‘˜0).  \n",
    "#         #we've alredy calculated it since the loop continues through to the very end of the sequence. \n",
    "#         #so the maximum of the final two states. \n",
    "        \n",
    "#         #so first set up the max equation. Give us the name of the final maximum state. \n",
    "#         max_final_state = max(grid, key = grid.get) #gives us the final state\n",
    "#         max_final_prob = grid[max_final_state] #gives the prob \n",
    "        \n",
    "#         # print(grid)\n",
    "#         # print(backward_pointer)\n",
    "            \n",
    "#         #Traceback: (ğ‘–=ğ‘‡â€¦1): ğœ‹âˆ—ğ‘–âˆ’1= ptrğ‘–(ğœ‹âˆ—ğ‘–).\n",
    "#         #which state did the max_final_state come from? \n",
    "#         result = [max_final_state] #putting the last element already into a list. \n",
    "#         for pos in reversed(range(len(sequence) -1)): #excluding the last element. \n",
    "#             result.append(backward_pointer[pos][max_final_state])\n",
    "#             # max_final_state = backward_pointer[pos][max_final_state]\n",
    "        \n",
    "        \n",
    "#         return result[::-1]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section of code will initialize your HMM with parameters as defined in the lecture slides\n",
    "# for the identification of CpG Islands.\n",
    "# All of this should be able to run whether or not you implement the Viterbi function!\n",
    "\n",
    "hidden_states = ('I', 'G') # CpG Island or Genome\n",
    "alphabet = ('A', 'C', 'G', 'T') # DNA Alphabet\n",
    "\n",
    "# These are the initial probabilities as defined in the lecture slides\n",
    "initial_probabilities = {\n",
    "    'I' : 0.1,\n",
    "    'G' : 0.9\n",
    "}\n",
    "\n",
    "# These are the probabilities of transitioning from outer state to inner state\n",
    "#  as defined in the lecture slides\n",
    "transition_probabilities = {\n",
    "    'I': { 'I' : 0.6, 'G' : 0.4 },\n",
    "    'G': { 'I' : 0.1, 'G' : 0.9 }\n",
    "}\n",
    "\n",
    "# These are the probabilites of each state emmitting each alphabet character\n",
    "emission_probabilities = {\n",
    "    'I': { 'A' : 0.1, 'C' : 0.4, 'G' : 0.4, 'T' : 0.1 },\n",
    "    'G': { 'A' : 0.4, 'C' : 0.1, 'G' : 0.1, 'T' : 0.4 }\n",
    "}\n",
    "\n",
    "# Build the model\n",
    "model = HMM(alphabet, hidden_states, transition_probabilities, emission_probabilities, initial_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACGCGATC\n",
      "G\n",
      "G\n",
      "G\n",
      "I\n",
      "G\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "G\n",
      "I\n",
      "G\n",
      "G\n",
      "GGGIIGGG\n",
      "ACGCGATCATACTATATTAGCTAAATAGATACGCGCGCGCGCGCGATATATATATATAGCTAATGATCGATTACCCCCCCCCCCAATTA\n",
      "G\n",
      "G\n",
      "G\n",
      "I\n",
      "G\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "G\n",
      "I\n",
      "G\n",
      "G\n",
      "G\n",
      "I\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "I\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "I\n",
      "G\n",
      "I\n",
      "G\n",
      "I\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "I\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "I\n",
      "G\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "G\n",
      "I\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "I\n",
      "G\n",
      "I\n",
      "G\n",
      "I\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "I\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "I\n",
      "G\n",
      "I\n",
      "G\n",
      "I\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "I\n",
      "G\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "G\n",
      "I\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "G\n",
      "GGGIIGGGGGGGGGGGGGGGGGGGGGGGGGGGGIIIIIIIIIIIIGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGIIIIIIIIIGGGGG\n"
     ]
    }
   ],
   "source": [
    "# Exact example from slides\n",
    "sequence = \"ACGCGATC\"\n",
    "print(sequence)\n",
    "print (''.join(model.viterbi(list(sequence))))\n",
    "\n",
    "# A slightly more complex example\n",
    "sequence = \"ACGCGATCATACTATATTAGCTAAATAGATACGCGCGCGCGCGCGATATATATATATAGCTAATGATCGATTACCCCCCCCCCCAATTA\"\n",
    "print(sequence)\n",
    "print (''.join(model.viterbi(list(sequence))))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "ACGCGATC\n",
    "GIIIIGGG\n",
    "ACGCGATCATACTATATTAGCTAAATAGATACGCGCGCGCGCGCGATATATATATATAGCTAATGATCGATTACCCCCCCCCCCAATTA\n",
    "GIIIIGGGGGGGGGGGGGGGGGGGGGGGGGGIIIIIIIIIIIIIIGGGGGGGGGGGGGGGGGGGGGGGGGGGGIIIIIIIIIIIGGGGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = ('Ai', 'Ci', 'Gi', 'Ti', 'Ag', 'Cg', 'Gg', 'Tg')\n",
    "alphabet = ('A', 'C', 'G', 'T')\n",
    "\n",
    "initial_probabilities = {\n",
    "    'Ai' : 0.125,\n",
    "    'Ci' : 0.125,\n",
    "    'Gi' : 0.125,\n",
    "    'Ti' : 0.125,\n",
    "    'Ag' : 0.125,\n",
    "    'Cg' : 0.125,\n",
    "    'Gg' : 0.125,\n",
    "    'Tg' : 0.125\n",
    "}\n",
    "\n",
    "transition_probabilities = {\n",
    "    'Ai': { 'Ai' : 0.2, 'Ci' : 0.36, 'Gi' : 0.2, 'Ti' : 0.2, 'Ag' : 0.01, 'Cg' : 0.01, 'Gg' : 0.01, 'Tg' : 0.01 },\n",
    "    'Ci': { 'Ai' : 0.1, 'Ci' : 0.1, 'Gi' : 0.66, 'Ti' : 0.1, 'Ag' : 0.01, 'Cg' : 0.01, 'Gg' : 0.01, 'Tg' : 0.01 },\n",
    "    'Gi': { 'Ai' : 0.1, 'Ci' : 0.39, 'Gi' : 0.1, 'Ti' : 0.1, 'Ag' : 0.1, 'Cg' : 0.01, 'Gg' : 0.1, 'Tg' : 0.1 },\n",
    "    'Ti': { 'Ai' : 0.2, 'Ci' : 0.36, 'Gi' : 0.2, 'Ti' : 0.2, 'Ag' : 0.01, 'Cg' : 0.01, 'Gg' : 0.01, 'Tg' : 0.01 },\n",
    "    'Ag': { 'Ai' : 0.01, 'Ci' : 0.1, 'Gi' : 0.01, 'Ti' : 0.01, 'Ag' : 0.2175, 'Cg' : 0.2175, 'Gg' : 0.2175, 'Tg' : 0.2175 },\n",
    "    'Cg': { 'Ai' : 0.01, 'Ci' : 0.1, 'Gi' : 0.01, 'Ti' : 0.01, 'Ag' : 0.2175, 'Cg' : 0.2175, 'Gg' : 0.2175, 'Tg' : 0.2175 },\n",
    "    'Gg': { 'Ai' : 0.01, 'Ci' : 0.1, 'Gi' : 0.01, 'Ti' : 0.01, 'Ag' : 0.2175, 'Cg' : 0.2175, 'Gg' : 0.2175, 'Tg' : 0.2175 },\n",
    "    'Tg': { 'Ai' : 0.01, 'Ci' : 0.1, 'Gi' : 0.01, 'Ti' : 0.01, 'Ag' : 0.2175, 'Cg' : 0.2175, 'Gg' : 0.2175, 'Tg' : 0.2175 }\n",
    "}\n",
    "\n",
    "emission_probabilities = {\n",
    "    'Ai': { 'A' : 1, 'C' : 0.001, 'G' : 0.001, 'T' : 0.001 },\n",
    "    'Ci': { 'A' : 0.001, 'C' : 1, 'G' : 0.001, 'T' : 0.001 },\n",
    "    'Gi': { 'A' : 0.001, 'C' : 0.001, 'G' : 1, 'T' : 0.001 },\n",
    "    'Ti': { 'A' : 0.001, 'C' : 0.001, 'G' : 0.001, 'T' : 1 },\n",
    "    'Ag': { 'A' : 1, 'C' : 0.001, 'G' : 0.001, 'T' : 0.001 },\n",
    "    'Cg': { 'A' : 0.001, 'C' : 1, 'G' : 0.001, 'T' : 0.001 },\n",
    "    'Gg': { 'A' : 0.001, 'C' : 0.001, 'G' : 1, 'T' : 0.001 },\n",
    "    'Tg': { 'A' : 0.001, 'C' :0.0010, 'G' : 0.001, 'T' : 1 }\n",
    "}\n",
    "\n",
    "model = HMM(alphabet, hidden_states, transition_probabilities, emission_probabilities, initial_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACGCGATCATACTATATTAGCTAAATAGATACGCGCGCGCGCGCGATATATATATATAGCTAATGATCGATTACCCCCCCCCCCAATTA\n",
      "ggIgIgggggggggggggggggggggggggggggIgIIIIIIIIIgggggggggggggggggggggggggggggggggggggggggggg\n"
     ]
    }
   ],
   "source": [
    "sequence = \"ACGCGATCATACTATATTAGCTAAATAGATACGCGCGCGCGCGCGATATATATATATAGCTAATGATCGATTACCCCCCCCCCCAATTA\"\n",
    "\n",
    "print(sequence)\n",
    "\n",
    "result = ''.join(model.viterbi(sequence))\n",
    "result = result.replace(\"A\", \"\")\n",
    "result = result.replace(\"C\", \"\")\n",
    "result = result.replace(\"G\", \"\")\n",
    "result = result.replace(\"T\", \"\")\n",
    "result = result.replace(\"i\", \"I\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "ACGCGATCATACTATATTAGCTAAATAGATACGCGCGCGCGCGCGATATATATATATAGCTAATGATCGATTACCCCCCCCCCCAATTA\n",
    "IIIIIggggggggggggggggggggggggggIIIIIIIIIIIIIIgggggggggggggggggggggggggggggggggggggggggggg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
